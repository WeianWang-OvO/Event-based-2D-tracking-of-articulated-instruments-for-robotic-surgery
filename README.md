# Event-based-2D-tracking-of-articulated-instruments-for-robotic-surgery

Authors: 

Fahd Qureshi, Weian Wang

Supervisors: 

Agostino Stilli, Beatrice Van Amsterdam, Emanuele Colleoni, Frans Chadebecq

Description: 

Surgical instrument detection and tracking is essential to provide safe tool-tissue interaction in robotically-assisted minimally invasive surgery (RAMIS). It further contributes to increase the autonomy of surgical robots and facilitates surgical skill assessment. Despite recent advances of learning-based approaches, the real-time tracking and consequently the 3D pose estimation of surgical tools remain challenging problems. To address these problems, we propose to rely on event-based cameras. Event-based cameras embed imaging-sensors responding to local change in brightness which allow them to capture movement and generate videos with high dynamic range and temporal resolution. This project will develop a real-time learning-based technique to automatically track articulated instruments in RAMIS (endoscopic images). Furthermore, this technique could be extended to estimate the 3D pose of articulated instruments.

Status: 

In progress...
